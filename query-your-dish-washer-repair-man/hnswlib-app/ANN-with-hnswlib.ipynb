{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Intro\n",
    "This example uses Approximate Nearest Neighbor Search (ANN) using [Hnswlib](https://github.com/nmslib/hnswlib/).\n",
    "\n",
    "Install it with: `pip install hnswlib` (along with other requirements)\n",
    "\n",
    "The embeddings model is 'msmarco-distilbert-base-v4' from SBERT\n",
    "\n",
    "The dataset we use is our own, (at ../dish-washer-data.csv); that gives us a way to compare with naive search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hnswlib\n",
    "!pip install pandas\n",
    "!pip3 install torch\n",
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/vast-jupyter/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import time\n",
    "import hnswlib\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'msmarco-distilbert-base-v4'\n",
    "embeddings_model = SentenceTransformer(model_name)\n",
    "embedding_size = 768    #Size of embeddings\n",
    "top_k_hits = 5         #Output k hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str, model: SentenceTransformer) -> list[float]:\n",
    "    embeddings = model.encode([text])\n",
    "    return embeddings\n",
    "\n",
    "def get_doc_embedding(text: str, model: SentenceTransformer) -> list[float]:\n",
    "    return get_embedding(text, model)\n",
    "\n",
    "def get_query_embedding(text: str, model: SentenceTransformer) -> list[float]:\n",
    "    return get_embedding(text, model)\n",
    "\n",
    "def compute_doc_embeddings(df: pd.DataFrame, model: SentenceTransformer) -> dict[tuple[str, str], list[float]]:\n",
    "    \"\"\"\n",
    "    Create an embedding for each row in the dataframe.\n",
    "    Return a dictionary that maps between each embedding vector and the index of the row that it corresponds to.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        idx: get_doc_embedding(r.content.replace(\"\\n\", \" \"), model) for idx, r in df.iterrows()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-computed embeddings from disc...\n",
      "Loading done.\n",
      "Length, corpus sentences:149\n",
      "Length, corpus embeddings:149\n",
      "one vector dimension: 768\n",
      "Sentence samples\n",
      "                                                              content  tokens\n",
      "title     heading                                                           \n",
      "Chapter_6 352       However, if you're a DIY'er, it's a BIG probl...     105\n",
      "          436       If your machine uses a blower to dry the dish...      85\n",
      "Chapter_3 174       Etching is caused by overly acidic conditions...     116\n",
      "Chapter_6 361       If you see dotted or shaded lines around a gr...      73\n",
      "          378       Sometimes you can eliminate possibilities jus...      97\n"
     ]
    }
   ],
   "source": [
    "embeddings_cache_path = f\"dishwasher-repair-manual-embeddings-{model_name.replace('/', '_')}.pkl\"\n",
    "\n",
    "#Check if embeddings cache path exists\n",
    "if not os.path.exists(embeddings_cache_path):\n",
    "    df = pd.read_csv('../dish-washer-data.csv')\n",
    "    df[\"tokens\"] = pd.to_numeric(df[\"tokens\"])  # convert column \"tokens\" of a DataFrame\n",
    "    df = df.set_index([\"title\", \"heading\"])\n",
    "    print(f\"{len(df)} rows in the data.\")\n",
    "    print(df.sample(10))\n",
    "    # TODO get some stats on max/min content length\n",
    "    corpus_size = df.shape[0]\n",
    "\n",
    "    # This could take a bit of time\n",
    "    print(\"Encoding the corpus. This might take a while...\")\n",
    "    corpus_embeddings = compute_doc_embeddings(df, embeddings_model)\n",
    "\n",
    "    print(\"Store file...\")\n",
    "    with open(embeddings_cache_path, \"wb\") as fOut:\n",
    "        pickle.dump({'sentences': df, 'embeddings': corpus_embeddings}, fOut)\n",
    "else:\n",
    "    print(\"Loading pre-computed embeddings from disc...\")\n",
    "    with open(embeddings_cache_path, \"rb\") as f_in:\n",
    "        cache_data = pickle.load(f_in)\n",
    "        corpus_sentences = cache_data['sentences']\n",
    "        corpus_embeddings = cache_data['embeddings']\n",
    "        corpus_embeddings = [v for k, v in corpus_embeddings.items()]\n",
    "        print(\"Loading done.\")\n",
    "        print(f'Length, corpus sentences:{len(corpus_sentences)}')\n",
    "        print(f'Length, corpus embeddings:{len(corpus_embeddings)}')\n",
    "        print(f'one vector dimension: {len(corpus_embeddings[0][0])}')\n",
    "\n",
    "        print(f\"Sentence samples\\n {corpus_sentences.sample(5)}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start creating HNSWLIB index\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148]\n",
      "shape (149, 768)\n",
      "corpus embeddings:\n",
      "[[ 0.19535312  0.3732101   0.00957511 ... -0.33160087  0.40261486\n",
      "   0.00784518]\n",
      " [ 0.2158837   0.24450128  0.04495094 ... -0.44080067  0.05832485\n",
      "  -0.31278768]\n",
      " [ 0.02364053 -0.06990882 -0.00177497 ... -0.30113485  0.51544154\n",
      "   0.23895846]\n",
      " ...\n",
      " [-0.24814965 -0.4099893   0.35149598 ... -0.10772216 -0.28299245\n",
      "  -0.83697766]\n",
      " [ 0.40227854 -0.41134086 -0.12460402 ... -0.07596575  0.05090303\n",
      "   0.19828165]\n",
      " [ 0.287303   -0.64436454  0.19014618 ...  0.16235892 -0.3381821\n",
      "  -0.32102224]]\n",
      "Saving index to: ./hnswlib.index\n"
     ]
    }
   ],
   "source": [
    "#Defining our hnswlib index\n",
    "index_path = \"./hnswlib.index\"\n",
    "index = hnswlib.Index(space = 'cosine', dim = embedding_size)\n",
    "\n",
    "if os.path.exists(index_path):\n",
    "    print(\"Loading index...\")\n",
    "    index.load_index(index_path)\n",
    "    print('Loading index done.')\n",
    "else:\n",
    "    ### Create the HNSWLIB index\n",
    "    print(\"Start creating HNSWLIB index\")\n",
    "    # TODO check is ef_consturction and M and appropriate for this dataset\n",
    "    index.init_index(max_elements = len(corpus_embeddings), ef_construction = 400, M = 64)\n",
    "\n",
    "    print(list(range(len(corpus_embeddings))))\n",
    "    # Then we train the index to find a suitable clustering\n",
    "    corpus_embeddings = np.array(corpus_embeddings).squeeze()\n",
    "    print('shape', corpus_embeddings.shape)\n",
    "    print(f'corpus embeddings:\\n{corpus_embeddings}')\n",
    "    index.add_items(corpus_embeddings, list(range(len(corpus_embeddings))))\n",
    "    # ?? index.add_items(corpus_embeddings, list(corpus_sentences.index))\n",
    "\n",
    "    print(\"Saving index to:\", index_path)\n",
    "    index.save_index(index_path)\n",
    "\n",
    "# Controlling the recall by setting ef:\n",
    "index.set_ef(50)  # ef should always be > top_k_hits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose questions\n",
    "# inp_question = \"Why is my dishwasher leaking?\"\n",
    "inp_question = \"Why do we use a dishwasher?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits\n",
      ", [{'corpus_id': np.uint64(1), 'score': np.float32(0.76414967)}, {'corpus_id': np.uint64(106), 'score': np.float32(0.63856494)}, {'corpus_id': np.uint64(0), 'score': np.float32(0.60734546)}, {'corpus_id': np.uint64(15), 'score': np.float32(0.6050055)}, {'corpus_id': np.uint64(3), 'score': np.float32(0.59901273)}]\n",
      "Input question: Why do we use a dishwasher?\n",
      "Results (after 0.344 seconds):\n",
      "\t0.764\t The main reason dishwashers exist is that they allow dishes to be washed in water much hotter than you can use when washing dishes by hand. This allows greater grease-cutting and sterilization of the dishes. They are NOT made to operate under cold water conditions or to ingest your disgusting, moldy leftovers, no matter what the sales literature says. And using cheap soap and hard water (without making some adjustments) can shorten their lives considerably.\n",
      "\t0.639\t Nowadays, dishwashers are being made as efficient as possible, due in no small part to government energy efficiency requirements. Heating water can use a lot of energy, so designers are mimimizing water usage and heater operation. The trick is in achieving a balance; that is, keeping enough hot, clean water in the tub to clean the dishes, while minimizing energy and water usage. In practical terms, this translates to trying to measure the water temp, and also how dirty the water is, using things like thermistors and turbidity sensors.\n",
      "\t0.607\t It seems like everyone I know has a different opinion about their dishwasher. Some seem to think that theirs is a Godsend and a lifesaver; others think it's a total waste of time, hot water and electricity. Truth is, everybody's right! Within their limitations, dishwashers can provide virtually sterile dishes, if that's what you need. Poorly used and poorly maintained, they can be a huge, inefficient pain in the neck.\n",
      "\t0.605\t It's important to know that washing dishes in a dishwasher is not just a matter of blowing hot water at them. It is not just simply a mechanical or hydraulic process. It is also a chemical process. The chemicals you use, from detergent to rinse agent, are extremely critical. I recommend you use the following stuff regularly: 1) Use dry (powder) Cascade\"â¢. The real stuff. Do not use liquid detergent. And especially do not use regular liquid dishsoap.\n",
      "\t0.599\t WHITE-WESTINGHOUSE DISHWASHERS: Frigidaire or D&M.: The main function of a dishwasher is to cut grease and sterilize the dishes by spraying hot soapy water at them. This is accomplished using an electric motorÂ and pump mounted at the bottom of a water reservoir, or tub. The pump takes suction from the tub and forces water up through spray arms, which spray the dishes. \n",
      "The water then simply drops back into the tub for recirculation.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "question_embedding = embeddings_model.encode(inp_question)\n",
    "\n",
    "# Use hnswlib knn_query method to find the top_k_hits\n",
    "corpus_ids, distances = index.knn_query(question_embedding, k=top_k_hits)\n",
    "\n",
    "# Extract corpus ids and scores for the query\n",
    "hits = [{'corpus_id': id, 'score': 1 - score} for id, score in zip(corpus_ids[0], distances[0])]\n",
    "hits = sorted(hits, key=lambda x: x['score'], reverse=True)\n",
    "end_time = time.time()\n",
    "print(f'Hits\\n, {hits}')\n",
    "\n",
    "print(\"Input question:\", inp_question)\n",
    "print(\"Results (after {:.3f} seconds):\".format(end_time-start_time))\n",
    "for hit in hits[0:top_k_hits]:\n",
    "    print(f\"\\t{hit['score']:.3f}\\t{corpus_sentences.iloc[hit['corpus_id']].content}\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct hits:\n",
      " [{'corpus_id': 1, 'score': 0.7641496062278748}, {'corpus_id': 106, 'score': 0.638565182685852}, {'corpus_id': 0, 'score': 0.6073455214500427}, {'corpus_id': 15, 'score': 0.60500568151474}, {'corpus_id': 3, 'score': 0.5990124940872192}]\n",
      "\t0.764\t The main reason dishwashers exist is that they allow dishes to be washed in water much hotter than you can use when washing dishes by hand. This allows greater grease-cutting and sterilization of the dishes. They are NOT made to operate under cold water conditions or to ingest your disgusting, moldy leftovers, no matter what the sales literature says. And using cheap soap and hard water (without making some adjustments) can shorten their lives considerably.\n",
      "\t0.639\t Nowadays, dishwashers are being made as efficient as possible, due in no small part to government energy efficiency requirements. Heating water can use a lot of energy, so designers are mimimizing water usage and heater operation. The trick is in achieving a balance; that is, keeping enough hot, clean water in the tub to clean the dishes, while minimizing energy and water usage. In practical terms, this translates to trying to measure the water temp, and also how dirty the water is, using things like thermistors and turbidity sensors.\n",
      "\t0.607\t It seems like everyone I know has a different opinion about their dishwasher. Some seem to think that theirs is a Godsend and a lifesaver; others think it's a total waste of time, hot water and electricity. Truth is, everybody's right! Within their limitations, dishwashers can provide virtually sterile dishes, if that's what you need. Poorly used and poorly maintained, they can be a huge, inefficient pain in the neck.\n",
      "\t0.605\t It's important to know that washing dishes in a dishwasher is not just a matter of blowing hot water at them. It is not just simply a mechanical or hydraulic process. It is also a chemical process. The chemicals you use, from detergent to rinse agent, are extremely critical. I recommend you use the following stuff regularly: 1) Use dry (powder) Cascade\"â¢. The real stuff. Do not use liquid detergent. And especially do not use regular liquid dishsoap.\n",
      "\t0.599\t WHITE-WESTINGHOUSE DISHWASHERS: Frigidaire or D&M.: The main function of a dishwasher is to cut grease and sterilize the dishes by spraying hot soapy water at them. This is accomplished using an electric motorÂ and pump mounted at the bottom of a water reservoir, or tub. The pump takes suction from the tub and forces water up through spray arms, which spray the dishes. \n",
      "The water then simply drops back into the tub for recirculation.\n",
      "\n",
      "Approximate Nearest Neighbor Recall@5: 100.00\n",
      "\n",
      "\n",
      "========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Approximate Nearest Neighbor (ANN) is not exact, it might miss entries with high cosine similarity\n",
    "# Here, we compute the recall of ANN compared to the exact results\n",
    "correct_hits = util.semantic_search(torch.tensor(question_embedding), \n",
    "                                    torch.tensor(corpus_embeddings).squeeze(), \n",
    "                                    top_k=top_k_hits)[0]\n",
    "\n",
    "print(f'Correct hits:\\n {correct_hits}')\n",
    "\n",
    "for hit in correct_hits[0:top_k_hits]:\n",
    "    print(f\"\\t{hit['score']:.3f}\\t{corpus_sentences.iloc[hit['corpus_id']].content}\")\n",
    "\n",
    "correct_hits_ids = set([hit['corpus_id'] for hit in correct_hits])\n",
    "\n",
    "ann_corpus_ids = set([hit['corpus_id'] for hit in hits])\n",
    "if len(ann_corpus_ids) != len(correct_hits_ids):\n",
    "    print(\"Approximate Nearest Neighbor returned a different number of results than expected\")\n",
    "\n",
    "recall = len(ann_corpus_ids.intersection(correct_hits_ids)) / len(correct_hits_ids)\n",
    "print(\"\\nApproximate Nearest Neighbor Recall@{}: {:.2f}\".format(top_k_hits, recall * 100))\n",
    "\n",
    "if recall < 1:\n",
    "    print(\"Missing results:\")\n",
    "    for hit in correct_hits[0:top_k_hits]:\n",
    "        if hit['corpus_id'] not in ann_corpus_ids:\n",
    "            print(\"\\t{:.3f}\\t{}\".format(hit['score'], corpus_sentences[hit['corpus_id']]))\n",
    "print(\"\\n\\n========\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c5ba64e8a2a59a6be0dd5b8a0149005a96dade111bc9e6b7c5d65266a44d405"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
